{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRGvE-Pt3x3c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np, scipy as sp, scipy.stats, os, sys, joblib\n",
    "import os, numpy as np, scipy as sp, scipy.io, scipy.io.wavfile\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaM1gC4B37JJ"
   },
   "outputs": [],
   "source": [
    "path = r'drive/MyDrive/Colab Notebooks/df_complete_data.pkl'\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9HTtXrm78dV"
   },
   "outputs": [],
   "source": [
    "\n",
    "#check correctness of dataframe loaded\n",
    "for i in range(68261):\n",
    "  if len(df[\"recording\"][i]) != 4096:\n",
    "    print(\"problem sir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fElXRT5T4a36"
   },
   "outputs": [],
   "source": [
    "new_df = df[['patient_id', 'murmur']]\n",
    "new_df = new_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHkvtE-h6uwl"
   },
   "outputs": [],
   "source": [
    "new_df = new_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6T9wZX1WyE83",
    "outputId": "9e991a3e-d132-440b-8358-6af6a631f3d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "695\n"
     ]
    }
   ],
   "source": [
    "nb_murmur_present = (new_df.loc[new_df['murmur'] == 1]).shape[0]\n",
    "nb_murmur_absent = (new_df.loc[new_df['murmur'] == 0]).shape[0]\n",
    "print(nb_murmur_present)\n",
    "print(nb_murmur_absent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "mzg9rqHzxyal",
    "outputId": "966caa33-43bd-4d3e-a66e-4e41a5c56663"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-956a418c-427b-49f0-8f29-a2dd814af69b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>murmur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2530.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13918.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14241.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14998.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>85340.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>85341.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>85343.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>85345.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>85349.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-956a418c-427b-49f0-8f29-a2dd814af69b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-956a418c-427b-49f0-8f29-a2dd814af69b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-956a418c-427b-49f0-8f29-a2dd814af69b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     patient_id  murmur\n",
       "0        2530.0     0.0\n",
       "1        9979.0     1.0\n",
       "2       13918.0     1.0\n",
       "3       14241.0     1.0\n",
       "4       14998.0     0.0\n",
       "..          ...     ...\n",
       "869     85340.0     0.0\n",
       "870     85341.0     0.0\n",
       "871     85343.0     1.0\n",
       "872     85345.0     0.0\n",
       "873     85349.0     0.0\n",
       "\n",
       "[874 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un2S1LxU675v"
   },
   "outputs": [],
   "source": [
    "list_id = new_df['patient_id']\n",
    "list_label = new_df['murmur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNAjMblwwWaG"
   },
   "outputs": [],
   "source": [
    "def get_balanced_dataset(X,y):\n",
    "  ones = np.where(np.array(y)==1)\n",
    "  zeros = np.where(np.array(y)==0)\n",
    "  ones = ones[0]\n",
    "  zeros = zeros[0]\n",
    "  trunc = ones.shape[0] - zeros.shape[0]\n",
    "  zeros = zeros[:trunc]\n",
    "  new_X=[]\n",
    "  new_y=[]\n",
    "  for i in ones:\n",
    "    new_X.append(X[i])\n",
    "    new_y.append(y[i])\n",
    "  for j in zeros:\n",
    "    new_X.append(X[j])\n",
    "    new_y.append(y[j])\n",
    "  return new_X,new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6O4idCkwaFz"
   },
   "outputs": [],
   "source": [
    "list_id,list_label = get_balanced_dataset(list_id,list_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uR6aqz5g9oOj"
   },
   "outputs": [],
   "source": [
    "id_train, id_valtest, label_train, label_valtest = train_test_split(list_id, list_label , test_size=0.2, random_state=42)\n",
    "id_val, id_test, label_val, label_test = train_test_split(id_valtest, label_valtest , test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlEJD1ce4H1O"
   },
   "outputs": [],
   "source": [
    "def select_rows(id_list,dframe):\n",
    "  #for id in list_id:\n",
    "  sub_df = df.loc[df['patient_id'].isin([int(id) for id in id_list])]\n",
    "  return sub_df\n",
    "\n",
    "df_train = select_rows(id_train,df)\n",
    "df_val = select_rows(id_val,df)\n",
    "df_test = select_rows(id_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2w-MxY1_ClQ",
    "outputId": "4e3cbd0b-5215-4b46-9b95-2bd770e04685"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12317"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train.loc[df_train['murmur'] == 0]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfbOL3Un_ESV"
   },
   "outputs": [],
   "source": [
    "X_train = np.vstack(df_train['recording'])\n",
    "y_train = np.array(df_train['murmur'])\n",
    "\n",
    "X_val = np.vstack(df_val['recording'])\n",
    "y_val = np.array(df_val['murmur'])\n",
    "\n",
    "X_test = np.vstack(df_test['recording'])\n",
    "y_test = np.array(df_test['murmur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAlU7MUoCi6r"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train),len(X_train[1]),1)\n",
    "X_val = X_val.reshape(len(X_val),len(X_val[1]),1)\n",
    "X_test = X_test.reshape(len(X_test),len(X_test[1]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4opRxvN_pmS"
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = tf.keras.layers.Input(shape=(input_shape[0],input_shape[1]))\n",
    "    #input_layer = tf.keras.layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[0], mask_zero=True)(input_layer)\n",
    "    #lstm1 = tf.keras.layers.LSTM(128)(input_layer)\n",
    "    #lstm1 = tf.keras.layers.Dropout(0.2)(lstm1)\n",
    "    #lstm2 = tf.keras.layers.LSTM(64)(lstm1)\n",
    "    #lstm2 = tf.keras.layers.Dropout(0.2)(lstm2)\n",
    "    conv1 = tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.ReLU()(conv1)\n",
    "    #pool1 = tf.keras.layers.MaxPool1D(pool_size=(3,), padding='same')(conv1)\n",
    "    conv2 = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = tf.keras.layers.ReLU()(conv2)\n",
    "    #pool2 = tf.keras.layers.MaxPool1D(pool_size=(3,), padding='same')(conv2)\n",
    "    #input_conv = tf.keras.layers.Permute((2,1))(input_layer)\n",
    "    conv3 = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.ReLU()(conv3)\n",
    "\n",
    "    #gap = tf.keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "    #concat = tf.keras.layers.Concatenate([lstm1,gap])\n",
    "    #lstm1 = tf.keras.layers.LSTM(32,return_sequences=True)(conv3)\n",
    "    #lstm1 = tf.keras.layers.Dropout(0.2)(lstm1)\n",
    "\n",
    "    #lstm1 = tf.keras.layers.LSTM(32,return_sequences=True)(lstm1)\n",
    "    #lstm1 = tf.keras.layers.Dropout(0.2)(lstm1)\n",
    "\n",
    "    gap = tf.keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    #dense_layer = tf.keras.layers.\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(gap)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_gayKfl_qdh",
    "outputId": "9d351f1b-00d3-43e6-cfd1-95d5001c1b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4096, 1)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 4096, 32)          128       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4096, 32)         128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 4096, 32)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4096, 64)          6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4096, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 4096, 64)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 4096, 128)         24704     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4096, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 4096, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,065\n",
      "Trainable params: 31,617\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9Mhwho0DfDG",
    "outputId": "7842e247-92d3-46f1-c960-4d0bcf9427da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 798/4637 [====>.........................] - ETA: 1:32:20 - loss: 979.3032 - acc: 0.5147"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "#model.summary()\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "#model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hyYFCrlJEGsk",
    "outputId": "e8d5a3c2-5569-4054-fe6a-6bcfb3e03440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e28162bb8076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/multi_head_attention_5/softmax/Softmax' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-26-e28162bb8076>\", line 21, in <module>\n      history = model.fit(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n      attention_output, attention_scores = self._compute_attention(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/attention/multi_head_attention.py\", line 526, in _compute_attention\n      attention_scores = self._masked_softmax(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/attention/multi_head_attention.py\", line 492, in _masked_softmax\n      return self._softmax(attention_scores, attention_mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/activation/softmax.py\", line 103, in call\n      return backend.softmax(inputs, axis=self.axis[0])\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 5416, in softmax\n      return tf.nn.softmax(x, axis=axis)\nNode: 'model_1/multi_head_attention_5/softmax/Softmax'\nOOM when allocating tensor with shape[8,4,4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/multi_head_attention_5/softmax/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_32387]"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "opt = SGD(lr=0.01)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    #optimizer=opt,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"acc\"],\n",
    "    #metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    np.array(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val,np.array(y_val)),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRjdR3E9M6bp",
    "outputId": "8cfa0b77-de32-4dfd-863b-db333ebaf181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6746770143508911\n",
      "Test accuracy: 0.6201739311218262\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYQLQItpOKBp",
    "outputId": "69b188cc-88b8-43a8-ba13-97d4cda1870c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 1s 9ms/step\n",
      "[[0.4194224 ]\n",
      " [0.23355131]\n",
      " [0.30243465]\n",
      " ...\n",
      " [0.36207542]\n",
      " [0.29892328]\n",
      " [0.23779908]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyOqTnS9W--A"
   },
   "outputs": [],
   "source": [
    "def check_max_pred(prd):\n",
    "  max=0\n",
    "  for i in prd:\n",
    "    if i[0] > max:\n",
    "      max = i[0]\n",
    "  print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vt9hHlHde5G2",
    "outputId": "9cadbda2-c63a-4041-a470-62f8ba8bcefb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9781276\n"
     ]
    }
   ],
   "source": [
    "check_max_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dh7gibaQiOsw"
   },
   "outputs": [],
   "source": [
    "list_patient_rows = list(df_test.groupby(['patient_id'])['patient_id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByfsYZiaiqj3"
   },
   "outputs": [],
   "source": [
    "def cumulative(lists): \n",
    "    cu_list = [] \n",
    "    length = len(lists) \n",
    "    cu_list = [sum(lists[0:x:1]) for x in range(0, length+1)] \n",
    "    return cu_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBeasPNClnpb"
   },
   "outputs": [],
   "source": [
    "pred_groupby_patient = np.split(pred,cumulative(list_patient_rows))\n",
    "pred_groupby_patient = pred_groupby_patient[:-1]\n",
    "\n",
    "df_test = df_test.astype({'murmur':'int'})\n",
    "y_test_grouped = df_test[['patient_id','murmur']].drop_duplicates()['murmur'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKJrhB9QwQ3_"
   },
   "outputs": [],
   "source": [
    "def mean_pred(prediction):\n",
    "  pred = []\n",
    "  for i in prediction:\n",
    "    lst = [ j[0] for j in i]\n",
    "    avg = sum(lst)/len(lst)\n",
    "    if avg > 0.5:\n",
    "      pred.append(1)\n",
    "    else:\n",
    "      pred.append(0)\n",
    "  return pred\n",
    "\n",
    "def majority_pred(prediction):\n",
    "  pred = []\n",
    "  for i in prediction:\n",
    "    lst = [ j[0] for j in i]\n",
    "    if (sum(elem > 0.5 for elem in lst)) > (len(lst)/2):\n",
    "      pred.append(1)\n",
    "    else:\n",
    "      pred.append(0)\n",
    "  return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYCSAcHFzHLy"
   },
   "outputs": [],
   "source": [
    "pred1 = mean_pred(pred_groupby_patient)\n",
    "pred2 = majority_pred(pred_groupby_patient)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoHq89-17e8x",
    "outputId": "157aff23-5b0b-45cd-8eb4-51810476b240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred1)\n",
    "print(pred2)\n",
    "print(y_test_grouped)\n",
    "print(accuracy_score(pred1 , y_test_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Va4k-0WH4FZw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SO30vCJawoVq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
